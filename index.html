<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->

  <title>A Deep Reinforcement Learning Approach to Configuration Sampling Problem</title>
  <meta name="description" content="">
  <meta name="author" content="">

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- FONT
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!--<link href="//fonts.googleapis.com/css?family=Raleway:400,300,600" rel="stylesheet" type="text/css">-->

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="stylesheet" href="./static_files/normalize.css">
  <link rel="stylesheet" href="./static_files/skeleton.css">
  <link rel="stylesheet" href="./static_files/styles.css">

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <!--<link rel="icon" type="image/png" href="images/favicon.png">-->

</head>
<body>

  <!-- Primary Page Layout
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <div class="container">
    <section class="header">
      <h1 class="title">RLSampler</h1>
      <br><br>
      <div>
        <img class="logo" src="./static_files/RLSampler.png" width="700">
      </div>
      <h4 class="subtitle">A Deep Reinforcement Learning Approach to<br>Configuration Sampling Problem</h4>
    </section>
    <br>
    <section class="summary">
      <p align="justify">
        Configurable software systems have become increasingly popular as they enable customized software variants. The main challenge in dealing with configuration problems is that the number of possible configurations grows exponentially as the number of features increases. Therefore, algorithms for testing customized software have to deal with the challenge of tractably finding potentially faulty configurations given exponentially large configurations.
        <br><br>To overcome this problem, prior works focused on sampling strategies to significantly reduce the number of generated configurations, guaranteeing a high t-wise coverage. <br><br>RLSampler is a deep reinforcement learning (DRL) based sampler that efficiently finds the trade-off between exploration and exploitation, allowing for the efficient identification of a minimal subset of configurations that covers all t-wise feature interactions while minimizing redundancy.
      </p>
      <p class="alert" style="text-align:left;">
        Amir Abolfazli, Jakob Spiegelberg, Gregory Palmer, and Avishek Anand.
        <i>A Deep Reinforcement Learning Approach to Configuration Sampling Problem.</i>
        In <i>IEEE International Conference on Data Mining (ICDM).</i> 2023.
      </p>
    </section>
    <section class="code-links">
      <a href="https://github.com/amir-abolfazli/RLSampler/tree/main/code" class="button">
        Code
      </a>
      <a href="https://github.com/amir-abolfazli/RLSampler/tree/main/code/cs_gym" class="button">
        CS-Gym
      </a>
      <a href="https://github.com/amir-abolfazli/RLSampler/tree/main/code/feature_models" class="button">
        Feature Models
      </a>
      <a href="https://ieeexplore.ieee.org/abstract/document/10415711" class="button">
        Paper
      </a>
    </section>
  </div>

<!-- End Document
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->


</body></html>
